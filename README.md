# Домашнее задание к занятию "`Репликация и масштабирование. Часть 2`" - `Рыбянцев Павел`

---

### Задание 1

Опишите основные преимущества использования масштабирования методами:

- активный master-сервер и пассивный репликационный slave-сервер; 
- master-сервер и несколько slave-серверов;


*Дайте ответ в свободной форме.*
```
1. Активный Master и пассивный Slave (Failover Pair)
    В этой схеме Master обрабатывает все запросы (чтение и запись), 
    а Slave находится в режиме ожидания, синхронно или асинхронно копируя данные.
    Преимущества:
    - Высокая отказоустойчивость (High Availability): Если Master выходит из строя, Slave его заменяет.
    - Целостность данных: Поскольку Slave не используется для чтения, 
        риск получения неактуальных данных минимален (особенно при синхронной репликации).
    - Упрощенная логика приложения: Приложению не требуется разделять потоки чтения/записи.
        Оно всегда обращается к одному активному узлу.

2. Master и несколько Slave-серверов (Read Scaling)
    Здесь Master принимает все операции записи (INSERT, UPDATE, DELETE),
    а нагрузка по чтению (SELECT) распределяется между несколькими Slave-серверами.
    Преимущества:
    - Горизонтальное масштабирование чтения: Если запросов на чтение становится слишком много,
        добавляем еще один Slave.
    - Снижение нагрузки на Master: Освобождая основной сервер от запросов на чтение,
        запись данных будет проходить быстрее.
    - Географическое распределение: Slave-серверы можно разместить в разных дата-центрах или регионах ближе к конечным пользователям,
        чтобы сократить задержки (latency).
    Безопасное создание бэкапов: Можно запускать резервное копирование на одном из Slave-серверов,
        абсолютно не замедляя работу основного приложения.
```
---

### Задание 2


Разработайте план для выполнения горизонтального и вертикального шаринга базы данных. База данных состоит из трёх таблиц: 

- пользователи, 
- книги, 
- магазины (столбцы произвольно). 

Опишите принципы построения системы и их разграничение или разбивку между базами данных.

*Пришлите блоксхему, где и что будет располагаться. Опишите, в каких режимах будут работать сервера.* 
```
Пользователи: Вертикальное шардирование.
    Данные разделены по составу колонок внутри одного логического узла.
    DB_Users_Main (Частые данные): 
        Хранит только id, name, email. 
        Эта база оптимизирована для сверхбыстрого чтения профилей и поиска по почте.
        Она легкая и кэшируется в оперативной памяти.
    DB_Users_Logs (Редкие данные): 
        Хранит тяжелые или редко используемые поля:
            password_hash, логи входов, биометрию.
        Зачем: 
            Чтобы при массовом просмотре списка пользователей
            база не «прокачивала» через себя тяжелые хеши паролей,
            которые не нужны для отображения имен.

Книги: Горизонтальное шардирование по диапазону id
    Данные разделены по строкам (записям) между физически разными серверами.
    Шард 1 (ID 1–5000): Хранит первую половину каталога.
    Шард 2 (ID 5001+): Хранит вторую половину каталога.
    Master-slave: Каждый шард имеет slave.
        Если основной сервер падает, реплика берет нагрузку на себя.
    Зачем: Масштабируемость. 
        Если книг станет миллион, мы просто добавим Шард 3 (ID 10001+) без остановки системы.

Магазины и Книги: Денормализация.
    Источник истины (DB_Stores):
        Таблица со всеми деталями магазинов (адреса, телефоны, регионы).
    Денормализованное поле в Книгах:
        В таблицы книг (Books) принудительно добавлена колонка region_store.
    Зачем:
    Без этого, чтобы найти «Все книги в Европе»,
    системе пришлось бы сначала спросить сервер магазинов об ID Европы,
    а потом опрашивать ВСЕ шарды книг.
    Теперь запрос «Дай книги региона EU» выполняется мгновенно внутри одного шарда.
```
![схема](/img/image.png)
```

Архитектура реализуется на основе СУБД PostgreSQL
    и с помощью конкретных инструментов:
        расширения Citus или fdw (Foreign Data Wrappers) для шардинга и Patroni для управления Master/Slave.
В Postgres роль роутера/балансировщика выполняет Координатор (в Citus) или Proxy-слой (на базе pgBouncer/HAProxy)

Как это работает:
1. По типу сущности (Вертикальный шардинг):
    Роутер анализирует схему запроса.
    В Postgres это часто реализуется через разные схемы (schemas) или отдельные базы (databases) на разных инстансах.
    Если запрос идет к public.users, прокси-слой перенаправляет соединение на кластер пользователей.

2. По хешу (Горизонтальный шардинг Книг):
    PostgreSQL использует метод Hash Sharding.
    Роутер берет book_id, прогоняет его через хеш-функцию и определяет, на какой «воркер» отправить запрос.
    2.1 Пример: Запрос SELECT * FROM books WHERE book_id = 105; превращается в обращение конкретно к ноде Shard_A

3. Дублирование таблицы магазинов (Reference Tables):
    Таблица Stores объявляется как Reference Table.
    Роутер знает, что она продублирована везде,
    и позволяет выполнять JOIN книг и магазинов прямо на месте 
    (локально на воркере) без пересылки данных между серверами.


```


## Дополнительные задания (со звёздочкой*)
Эти задания дополнительные, то есть не обязательные к выполнению, и никак не повлияют на получение вами зачёта по этому домашнему заданию. Вы можете их выполнить, если хотите глубже шире разобраться в материале.

---
### Задание 3*

Выполните настройку выбранных методов шардинга из задания 2.

*Пришлите конфиг Docker и SQL скрипт с командами для базы данных*.
